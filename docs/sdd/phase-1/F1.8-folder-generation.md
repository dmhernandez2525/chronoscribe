# F1.8 - Per-Document Folder Generation

## Overview

| Attribute | Value |
|-----------|-------|
| Feature ID | F1.8 |
| Phase | 1 (MVP) |
| Priority | P0 |
| Status | Planned |
| Module | `chronoscribe.storage.folder_generator` |

## Description

Create an organized folder structure for each processed document. Each document gets its own folder containing all artifacts: original file, normalized image, transcription files, analysis metadata, and summary.

## Requirements

### Functional Requirements

1. **FR1.8.1** - Create folder with format: `YYYY-MM-DD_type_sequence/`
2. **FR1.8.2** - Store all artifacts: original, normalized, transcription, analysis, metadata
3. **FR1.8.3** - Handle undated documents in `archive/undated/` folder
4. **FR1.8.4** - Use sequence numbers to prevent collisions
5. **FR1.8.5** - Sanitize filenames (no special characters)
6. **FR1.8.6** - Maintain chronological organization: `archive/YYYY/MM/`

### Non-Functional Requirements

1. **NFR1.8.1** - Folder creation: < 100ms
2. **NFR1.8.2** - Atomic operations (no partial folders)
3. **NFR1.8.3** - Handle concurrent processing

## Technical Design

### Folder Structure

```
~/ChronoScribe/archive/
├── 2019/
│   ├── 03/
│   │   ├── 2019-03-15_invention_001/
│   │   │   ├── original.png
│   │   │   ├── normalized.png
│   │   │   ├── transcription.txt
│   │   │   ├── transcription.md
│   │   │   ├── analysis.json
│   │   │   ├── metadata.json
│   │   │   └── summary.txt
│   │   └── 2019-03-15_notes_002/
│   │       └── ...
│   └── 04/
│       └── ...
├── 2020/
│   └── ...
└── undated/
    ├── undated_sketch_001/
    │   └── ...
    └── undated_notes_002/
        └── ...
```

### Type Definitions

```python
from dataclasses import dataclass
from pathlib import Path
from datetime import date

@dataclass
class FolderContents:
    """Contents of a document folder."""
    folder_path: Path
    original: Path
    normalized: Path
    transcription_txt: Path
    transcription_md: Path
    analysis_json: Path
    metadata_json: Path
    summary_txt: Path

@dataclass
class FolderGeneratorConfig:
    """Configuration for folder generation."""
    archive_path: Path
    undated_folder: str = "undated"
    filename_max_length: int = 50
```

### Implementation

```python
import json
import re
import shutil
from datetime import date
from pathlib import Path
from threading import Lock

class FolderGenerator:
    """
    Generates organized folder structure for processed documents.
    """

    def __init__(self, config: FolderGeneratorConfig):
        self.config = config
        self._sequence_lock = Lock()
        self._sequence_cache: dict[str, int] = {}

    def create_folder(
        self,
        document_date: date | None,
        document_type: str,
        document_id: str,
    ) -> FolderContents:
        """
        Create a folder for a document with all artifact paths.

        Args:
            document_date: The document's primary date (or None if undated)
            document_type: Category/type of document (e.g., "invention", "notes")
            document_id: Unique document ID

        Returns:
            FolderContents with paths to all artifacts
        """
        # Determine base path
        if document_date:
            year = str(document_date.year)
            month = f"{document_date.month:02d}"
            date_str = document_date.isoformat()
            base_path = self.config.archive_path / year / month
        else:
            date_str = "undated"
            base_path = self.config.archive_path / self.config.undated_folder

        # Sanitize type for folder name
        safe_type = self._sanitize_name(document_type)

        # Get sequence number
        sequence = self._get_next_sequence(base_path, date_str, safe_type)

        # Create folder name
        folder_name = f"{date_str}_{safe_type}_{sequence:03d}"
        folder_path = base_path / folder_name

        # Create folder atomically
        folder_path.mkdir(parents=True, exist_ok=True)

        return FolderContents(
            folder_path=folder_path,
            original=folder_path / "original",  # Extension added later
            normalized=folder_path / "normalized.png",
            transcription_txt=folder_path / "transcription.txt",
            transcription_md=folder_path / "transcription.md",
            analysis_json=folder_path / "analysis.json",
            metadata_json=folder_path / "metadata.json",
            summary_txt=folder_path / "summary.txt",
        )

    def populate_folder(
        self,
        folder: FolderContents,
        original_path: Path,
        normalized_path: Path,
        transcription: str,
        analysis: dict,
        metadata: dict,
    ) -> None:
        """
        Populate a folder with all artifacts.

        Args:
            folder: FolderContents with paths
            original_path: Path to original file
            normalized_path: Path to normalized image
            transcription: Transcription text
            analysis: Analysis result dict
            metadata: Document metadata dict
        """
        # Copy original with correct extension
        original_ext = original_path.suffix
        original_dest = folder.original.with_suffix(original_ext)
        shutil.copy2(original_path, original_dest)

        # Copy normalized
        shutil.copy2(normalized_path, folder.normalized)

        # Write transcription (plain text)
        folder.transcription_txt.write_text(transcription, encoding="utf-8")

        # Write transcription (markdown with metadata)
        md_content = self._format_markdown(transcription, metadata, analysis)
        folder.transcription_md.write_text(md_content, encoding="utf-8")

        # Write analysis
        folder.analysis_json.write_text(
            json.dumps(analysis, indent=2, default=str),
            encoding="utf-8",
        )

        # Write metadata
        metadata["archive_path"] = str(folder.folder_path)
        folder.metadata_json.write_text(
            json.dumps(metadata, indent=2, default=str),
            encoding="utf-8",
        )

        # Write summary
        summary = analysis.get("summary", "No summary available.")
        folder.summary_txt.write_text(summary, encoding="utf-8")

    def _sanitize_name(self, name: str) -> str:
        """Sanitize a name for use in folder/file names."""
        # Remove or replace problematic characters
        sanitized = re.sub(r"[^\w\s-]", "", name.lower())
        sanitized = re.sub(r"[\s_]+", "-", sanitized)
        sanitized = sanitized.strip("-")

        # Limit length
        if len(sanitized) > self.config.filename_max_length:
            sanitized = sanitized[: self.config.filename_max_length]

        return sanitized or "document"

    def _get_next_sequence(
        self,
        base_path: Path,
        date_str: str,
        doc_type: str,
    ) -> int:
        """Get the next sequence number for a date/type combination."""
        cache_key = f"{base_path}/{date_str}_{doc_type}"

        with self._sequence_lock:
            if cache_key in self._sequence_cache:
                self._sequence_cache[cache_key] += 1
                return self._sequence_cache[cache_key]

            # Find existing folders matching pattern
            if base_path.exists():
                pattern = f"{date_str}_{doc_type}_*"
                existing = list(base_path.glob(pattern))
                if existing:
                    # Extract highest sequence number
                    max_seq = 0
                    for folder in existing:
                        match = re.search(r"_(\d{3})$", folder.name)
                        if match:
                            max_seq = max(max_seq, int(match.group(1)))
                    self._sequence_cache[cache_key] = max_seq + 1
                    return self._sequence_cache[cache_key]

            self._sequence_cache[cache_key] = 1
            return 1

    def _format_markdown(
        self,
        transcription: str,
        metadata: dict,
        analysis: dict,
    ) -> str:
        """Format transcription as Markdown with frontmatter."""
        # Build frontmatter
        frontmatter_fields = []

        if metadata.get("date"):
            frontmatter_fields.append(f"date: {metadata['date']}")

        if analysis.get("document_type"):
            frontmatter_fields.append(f"type: {analysis['document_type']}")

        if analysis.get("suggested_tags"):
            tags = ", ".join(analysis["suggested_tags"])
            frontmatter_fields.append(f"tags: [{tags}]")

        if metadata.get("original_filename"):
            frontmatter_fields.append(f"source: {metadata['original_filename']}")

        frontmatter = "\n".join(frontmatter_fields)

        # Build document
        md = f"""---
{frontmatter}
---

# Transcription

{transcription}

---

## Summary

{analysis.get('summary', 'No summary available.')}

## Entities

"""
        # Add entities if present
        entities = analysis.get("entities", {})
        for entity_type, values in entities.items():
            if values:
                md += f"- **{entity_type.title()}**: {', '.join(values)}\n"

        return md

    def get_folder_for_document(self, document_id: str) -> FolderContents | None:
        """Find the folder for an existing document."""
        # Search in archive
        for year_dir in self.config.archive_path.iterdir():
            if not year_dir.is_dir():
                continue

            for month_dir in year_dir.iterdir():
                if not month_dir.is_dir():
                    continue

                for folder in month_dir.iterdir():
                    metadata_path = folder / "metadata.json"
                    if metadata_path.exists():
                        try:
                            metadata = json.loads(metadata_path.read_text())
                            if metadata.get("id") == document_id:
                                return self._folder_contents_from_path(folder)
                        except json.JSONDecodeError:
                            continue

        return None

    def _folder_contents_from_path(self, folder_path: Path) -> FolderContents:
        """Create FolderContents from existing folder."""
        # Find original file (could have various extensions)
        original = None
        for ext in [".png", ".jpg", ".jpeg", ".tiff", ".pdf", ".heic"]:
            candidate = folder_path / f"original{ext}"
            if candidate.exists():
                original = candidate
                break

        return FolderContents(
            folder_path=folder_path,
            original=original or folder_path / "original",
            normalized=folder_path / "normalized.png",
            transcription_txt=folder_path / "transcription.txt",
            transcription_md=folder_path / "transcription.md",
            analysis_json=folder_path / "analysis.json",
            metadata_json=folder_path / "metadata.json",
            summary_txt=folder_path / "summary.txt",
        )
```

## Testing Strategy

### Unit Tests

```python
def test_sanitize_name():
    generator = FolderGenerator(config)

    assert generator._sanitize_name("Invention Sketch") == "invention-sketch"
    assert generator._sanitize_name("Notes/Ideas") == "notesideas"
    assert generator._sanitize_name("  Test  ") == "test"

def test_create_folder_dated():
    generator = FolderGenerator(config)
    doc_date = date(2019, 3, 15)

    folder = generator.create_folder(doc_date, "invention", "doc123")

    assert "2019" in str(folder.folder_path)
    assert "03" in str(folder.folder_path)
    assert "2019-03-15_invention_001" in str(folder.folder_path)

def test_create_folder_undated():
    generator = FolderGenerator(config)

    folder = generator.create_folder(None, "notes", "doc456")

    assert "undated" in str(folder.folder_path)
    assert "undated_notes_001" in str(folder.folder_path)

def test_sequence_increments():
    generator = FolderGenerator(config)
    doc_date = date(2019, 3, 15)

    folder1 = generator.create_folder(doc_date, "notes", "doc1")
    folder2 = generator.create_folder(doc_date, "notes", "doc2")

    assert "_001" in folder1.folder_path.name
    assert "_002" in folder2.folder_path.name
```

## Acceptance Criteria

- [ ] Folders created with format `YYYY-MM-DD_type_sequence/`
- [ ] All artifacts stored: original, normalized, transcription, analysis, metadata
- [ ] Undated documents go to `archive/undated/`
- [ ] Sequence numbers prevent collisions
- [ ] Filenames sanitized (no special characters)
- [ ] Chronological organization `archive/YYYY/MM/`
- [ ] Markdown transcription includes frontmatter
- [ ] Concurrent processing handled safely
- [ ] Folder creation < 100ms
